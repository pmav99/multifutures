{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Overview","text":""},{"location":"index.html#multifutures","title":"<code>multifutures</code>","text":"<p>Multiprocessing/multithreading made easy!</p>"},{"location":"index.html#example","title":"Example","text":"<pre><code>import multifutures as mf\n\n\ndef return_square(number: float) -&gt; float:\n    squared = number**2\n    return squared\n\n\nresults = mf.multiprocess(\n    func=return_square,\n    func_kwargs=[{\"number\": i} for i in range(10)],\n)\n\nfor result in results:\n    print(result)\n</code></pre> <p>Will print:</p> <pre><code>FutureResult(exception=None, kwargs={'number': 0}, result=0)\nFutureResult(exception=None, kwargs={'number': 1}, result=1)\nFutureResult(exception=None, kwargs={'number': 2}, result=4)\nFutureResult(exception=None, kwargs={'number': 3}, result=9)\nFutureResult(exception=None, kwargs={'number': 4}, result=16)\nFutureResult(exception=None, kwargs={'number': 5}, result=25)\nFutureResult(exception=None, kwargs={'number': 6}, result=36)\nFutureResult(exception=None, kwargs={'number': 7}, result=49)\nFutureResult(exception=None, kwargs={'number': 8}, result=64)\nFutureResult(exception=None, kwargs={'number': 9}, result=81)\n</code></pre>"},{"location":"api-multi.html","title":"multi","text":""},{"location":"api-multi.html#multifutures.multiprocess","title":"multifutures.multiprocess","text":"<pre><code>multiprocess(\n    func: collections.abc.Callable[..., typing.Any],\n    func_kwargs: collections.abc.Collection[dict[str, typing.Any]],\n    *,\n    max_workers: int | None = None,\n    executor: multifutures._common.ExecutorProtocol | None = None,\n    check: bool = False,\n    include_kwargs: bool = True,\n    progress_bar: multifutures._common.ProgressBarProtocol | bool | None = True\n) -&gt; list[multifutures._multi.FutureResult]\n</code></pre> <p>Call <code>func</code> over all the items of <code>func_kwargs</code> using a multiprocessing Pool and return a list of FutureResult objects.</p> <p>The pool by default is an instance of loky.ProcessPoolExecutor, or, if <code>loky</code> is not installed, an instance of concurrent.futures.ProcessPoolExecutor using the <code>spawn</code> multiprocessing context.</p> <p>The pool size can be limited with <code>max_workers</code>. If more control is needed, e.g. to use a different multiprocessing context, then the caller should directly pass a <code>ProcessPoolExecutor</code> instance to <code>executor</code>. For example:</p> <pre><code># Customize executor\nmp_context = multiprocessing.get_context(\"forkserver\")\nexecutor = concurrent.futures.ProcessPoolExecutor(max_workers=4, mp_context=mp_context)\nmultiprocess(func, func_kwargs, executor=executor)\n</code></pre> <p>The progress of the pool's workers can be monitored by using a tqdm based progress bar. The progress bar is displayed by default. Disabling the progress bar is possible by passing <code>progress_bar=False</code>. Further customizing of the progress bar should be done by creating a <code>tqdm.tqdm</code> instance and passing it as an argument to <code>progress_bar</code>. For example:</p> <pre><code># Run without a progress bar\nresults = multithread(func, func_kwargs, progress_bar=False)\n\n# Run with a rich based progress bar\nrich_based_progress_bar = tqdm.rich.tqdm(func_kwargs)\nresults = multithread(func, func_kwargs, progress_bar=rich_based_progress_bar)\n</code></pre> PARAMETER  DESCRIPTION <code>func</code> <p>The function that will be scheduled for execution via multiprocessing.</p> <p> TYPE: <code>collections.abc.Callable[..., typing.Any]</code> </p> <code>func_kwargs</code> <p>A Collection of dictionaries that will be used for the calls of <code>func</code>.</p> <p> TYPE: <code>collections.abc.Collection[dict[str, typing.Any]]</code> </p> <code>executor</code> <p>A multiprocessing Executor instance. Defaults to loky.get_reusable_executor(), which uses the <code>loky</code> multiprocessing context (more info). If loky is not installed, it defaults to Standard Library's ProcessPoolExecutor with the <code>spawn</code> multiprocessing start method (more info)</p> <p> TYPE: <code>multifutures._common.ExecutorProtocol | None</code> DEFAULT: <code>None</code> </p> <code>check</code> <p>If <code>True</code> then if any of the <code>func</code> calls raised an exception, an ExceptionGroup containing all the exceptions will be raised.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>include_kwargs</code> <p>A boolean flag indicating whether the keyword arguments of the functions will be present in the FurureResult object. Setting this to <code>False</code> is useful for keeping memory usage down when the input are \"heavy\" objects like xarray.Dataset etc.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>progress_bar</code> <p>An instance of a progress bar implementing the <code>tqdm</code> API. Defaults to <code>tqdm.auto.tqdm</code>.</p> <p> TYPE: <code>multifutures._common.ProgressBarProtocol | bool | None</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>list[multifutures._multi.FutureResult]</code> <p>A list of FutureResult objects. Each object will contain the output of <code>func(**func_kwargs[i])</code> or an <code>Exception</code>.</p> RAISES DESCRIPTION <code>exceptiongroup.ExceptionGroup</code> <p>If any of the function calls raises an exception and <code>check</code> is True.</p> Source code in <code>multifutures/_multi.py</code> <pre><code>def multiprocess(\n    func: abc.Callable[..., T.Any],\n    func_kwargs: abc.Collection[dict[str, T.Any]],\n    *,\n    max_workers: int | None = None,\n    executor: ExecutorProtocol | None = None,\n    check: bool = False,\n    include_kwargs: bool = True,\n    progress_bar: ProgressBarProtocol | bool | None = True,\n) -&gt; list[FutureResult]:\n    \"\"\"\n    Call `func` over all the items of `func_kwargs` using a multiprocessing Pool\n    and return a list of [FutureResult][multifutures.FutureResult] objects.\n\n    The pool by default is an instance of [loky.ProcessPoolExecutor](https://loky.readthedocs.io/en/stable/),\n    or, if `loky` is not installed, an instance of\n    [concurrent.futures.ProcessPoolExecutor][concurrent.futures.ProcessPoolExecutor]\n    using the `spawn` multiprocessing context.\n\n    The pool size can be limited with `max_workers`. If more control is needed, e.g. to use a different\n    multiprocessing context, then the caller should directly pass a `ProcessPoolExecutor`\n    instance to `executor`. For example:\n\n    ``` python\n    # Customize executor\n    mp_context = multiprocessing.get_context(\"forkserver\")\n    executor = concurrent.futures.ProcessPoolExecutor(max_workers=4, mp_context=mp_context)\n    multiprocess(func, func_kwargs, executor=executor)\n    ```\n\n    The progress of the pool's workers can be monitored by using a\n    [tqdm](https://tqdm.github.io/) based progress bar.\n    The progress bar is displayed by default.\n    Disabling the progress bar is possible by passing `progress_bar=False`.\n    Further customizing of the progress bar should be done by creating a `tqdm.tqdm`\n    instance and passing it as an argument to `progress_bar`. For example:\n\n    ``` python\n    # Run without a progress bar\n    results = multithread(func, func_kwargs, progress_bar=False)\n\n    # Run with a rich based progress bar\n    rich_based_progress_bar = tqdm.rich.tqdm(func_kwargs)\n    results = multithread(func, func_kwargs, progress_bar=rich_based_progress_bar)\n    ```\n\n    Arguments:\n        func: The function that will be scheduled for execution via multiprocessing.\n        func_kwargs: A Collection of dictionaries that will be used for the calls of `func`.\n        executor: A multiprocessing [Executor][concurrent.futures.Executor] instance.\n            Defaults to [loky.get_reusable_executor()][loky.get_reusable_executor],\n            which uses the `loky` multiprocessing context\n            ([more info](https://loky.readthedocs.io/en/stable/API.html#processes-start-methods-in-loky)).\n            If [loky][loky] is not installed, it defaults to Standard Library's\n            [ProcessPoolExecutor][concurrent.futures.ProcessPoolExecutor] with the `spawn` multiprocessing\n            start method ([more info](https://docs.python.org/3/library/multiprocessing.html#multiprocessing-start-methods))\n        check: If `True` then if any of the `func` calls raised an exception, an\n            [ExceptionGroup][ExceptionGroup] containing all the exceptions will be raised.\n        include_kwargs: A boolean flag indicating whether the keyword arguments of the\n            functions will be present in the [FurureResult][multifutures.FutureResult]\n            object. Setting this to `False` is useful for keeping memory usage down when\n            the input are \"heavy\" objects like [xarray.Dataset][xarray.Dataset] etc.\n        progress_bar: An instance of a progress bar implementing the `tqdm` API. Defaults to\n            `tqdm.auto.tqdm`.\n\n    Returns:\n        A list of [FutureResult][multifutures.FutureResult] objects. Each object\n            will contain the output of `func(**func_kwargs[i])` or an `Exception`.\n\n    Raises:\n        exceptiongroup.ExceptionGroup: If any of the function calls raises an exception and `check` is True.\n\n    \"\"\"\n    progress_bar = _resolve_progress_bar(progress_bar, func_kwargs)\n    executor = _resolve_multiprocess_executor(executor=executor, max_workers=max_workers)\n    results = _multi(\n        executor=executor,\n        func=func,\n        func_kwargs=func_kwargs,\n        include_kwargs=include_kwargs,\n        progress_bar=progress_bar,\n        check=check,\n    )\n    return results\n</code></pre>"},{"location":"api-multi.html#multifutures.multithread","title":"multifutures.multithread","text":"<pre><code>multithread(\n    func: collections.abc.Callable[..., typing.Any],\n    func_kwargs: collections.abc.Collection[dict[str, typing.Any]],\n    *,\n    max_workers: int | None = None,\n    executor: multifutures._common.ExecutorProtocol | None = None,\n    check: bool = False,\n    include_kwargs: bool = True,\n    progress_bar: multifutures._common.ProgressBarProtocol | bool | None = True\n) -&gt; list[multifutures._multi.FutureResult]\n</code></pre> <p>Call <code>func</code> over all the items of <code>func_kwargs</code> using a multithreading Pool and return a list of FutureResult objects.</p> <p>The pool by default is an instance of ThreadPoolExecutor. The pool size can be limited with <code>max_workers</code>. If more control is needed, then the caller should directly pass a ThreadPoolExecutor instance to <code>executor</code>. For example:</p> <pre><code># Customize executor\nexecutor = concurrent.futures.ThreadPoolExecutor(\n    max_workers=4, thread_name_prefix=\"AAA\"\n)\nmultithread(func, func_kwargs, executor=executor)\n</code></pre> <p>The progress of the pool's workers can be monitored by using a tqdm based progress bar. The progress bar is displayed by default. Disabling the progress bar is possible by passing <code>progress_bar=False</code>. Further customizing of the progress bar should be done by creating a <code>tqdm.tqdm</code> instance and passing it as an argument to <code>progress_bar</code>. For example:</p> <pre><code># Run without a progress bar\nresults = multithread(func, func_kwargs, progress_bar=False)\n\n# Run with a rich based progress bar\nrich_based_progress_bar = tqdm.rich.tqdm(func_kwargs)\nresults = multithread(func, func_kwargs, progress_bar=rich_based_progress_bar)\n</code></pre> PARAMETER  DESCRIPTION <code>func</code> <p>The function that will be scheduled for execution via multithreading.</p> <p> TYPE: <code>collections.abc.Callable[..., typing.Any]</code> </p> <code>func_kwargs</code> <p>A Collection of dictionaries that will be used for the calls of <code>func</code>.</p> <p> TYPE: <code>collections.abc.Collection[dict[str, typing.Any]]</code> </p> <code>executor</code> <p>The multithreading Executor instance that we want to use. Defaults to the standard library's ThreadPoolExecutor.</p> <p> TYPE: <code>multifutures._common.ExecutorProtocol | None</code> DEFAULT: <code>None</code> </p> <code>check</code> <p>If <code>True</code> then if any of the <code>func</code> calls raised an exception, an ExceptionGroup containing all the exceptions will be raised.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>include_kwargs</code> <p>A boolean flag indicating whether the keyword arguments of the functions will be present in the FurureResult object. Setting this to <code>False</code> is useful for keeping memory usage down when the input are \"heavy\" objects like xarray.Dataset etc.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>progress_bar</code> <p>An instance of a progress bar implementing the <code>tqdm</code> API. Defaults to <code>tqdm.auto.tqdm</code>.</p> <p> TYPE: <code>multifutures._common.ProgressBarProtocol | bool | None</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>list[multifutures._multi.FutureResult]</code> <p>A list of FutureResult objects. Each object will contain the output of <code>func(**func_kwarg)</code> or an <code>Exception</code>.</p> RAISES DESCRIPTION <code>exceptiongroup.ExceptionGroup</code> <p>If any of the function calls raises an exception and <code>check</code> is True.</p> Source code in <code>multifutures/_multi.py</code> <pre><code>def multithread(\n    func: abc.Callable[..., T.Any],\n    func_kwargs: abc.Collection[dict[str, T.Any]],\n    *,\n    max_workers: int | None = None,\n    executor: ExecutorProtocol | None = None,\n    check: bool = False,\n    include_kwargs: bool = True,\n    progress_bar: ProgressBarProtocol | bool | None = True,\n) -&gt; list[FutureResult]:\n    \"\"\"\n    Call `func` over all the items of `func_kwargs` using a multithreading Pool\n    and return a list of [FutureResult][multifutures.FutureResult] objects.\n\n    The pool by default is an instance of [ThreadPoolExecutor][concurrent.futures.ThreadPoolExecutor].\n    The pool size can be limited with `max_workers`. If more control is needed,\n    then the caller should directly pass a [ThreadPoolExecutor][concurrent.futures.ThreadPoolExecutor]\n    instance to `executor`. For example:\n\n    ``` python\n    # Customize executor\n    executor = concurrent.futures.ThreadPoolExecutor(\n        max_workers=4, thread_name_prefix=\"AAA\"\n    )\n    multithread(func, func_kwargs, executor=executor)\n    ```\n\n    The progress of the pool's workers can be monitored by using a\n    [tqdm](https://tqdm.github.io/) based progress bar.\n    The progress bar is displayed by default.\n    Disabling the progress bar is possible by passing `progress_bar=False`.\n    Further customizing of the progress bar should be done by creating a `tqdm.tqdm`\n    instance and passing it as an argument to `progress_bar`. For example:\n\n    ``` python\n    # Run without a progress bar\n    results = multithread(func, func_kwargs, progress_bar=False)\n\n    # Run with a rich based progress bar\n    rich_based_progress_bar = tqdm.rich.tqdm(func_kwargs)\n    results = multithread(func, func_kwargs, progress_bar=rich_based_progress_bar)\n    ```\n\n    Arguments:\n        func: The function that will be scheduled for execution via multithreading.\n        func_kwargs: A Collection of dictionaries that will be used for the calls of `func`.\n        executor: The multithreading [Executor][concurrent.futures.Executor] instance that we want to use.\n            Defaults to the standard library's [ThreadPoolExecutor][concurrent.futures.ThreadPoolExecutor].\n        check: If `True` then if any of the `func` calls raised an exception, an\n            [ExceptionGroup][ExceptionGroup] containing all the exceptions will be raised.\n        include_kwargs: A boolean flag indicating whether the keyword arguments of the\n            functions will be present in the [FurureResult][multifutures.FutureResult]\n            object. Setting this to `False` is useful for keeping memory usage down when\n            the input are \"heavy\" objects like [xarray.Dataset][xarray.Dataset] etc.\n        progress_bar: An instance of a progress bar implementing the `tqdm` API. Defaults to\n            `tqdm.auto.tqdm`.\n\n    Returns:\n        A list of [FutureResult][multifutures.FutureResult] objects. Each object\n            will contain the output of `func(**func_kwarg)` or an `Exception`.\n\n    Raises:\n        exceptiongroup.ExceptionGroup: If any of the function calls raises an exception and `check` is True.\n\n    \"\"\"\n    progress_bar = _resolve_progress_bar(progress_bar, func_kwargs)\n    executor = _resolve_multithreading_executor(executor=executor, max_workers=max_workers)\n    results = _multi(\n        executor=executor,\n        func=func,\n        func_kwargs=func_kwargs,\n        include_kwargs=include_kwargs,\n        progress_bar=progress_bar,\n        check=check,\n    )\n    return results\n</code></pre>"},{"location":"api-multi.html#multifutures.FutureResult","title":"multifutures.FutureResult  <code>dataclass</code>","text":"<p>A dataclass that holds the results of a function executed via multiprocess or multithread.</p> Note <p>Not meant to be instantiated directly.</p> <p>For example in the following snippet, <code>results</code> is going to be a list of <code>FutureResult</code> objects</p> <pre><code>&gt;&gt;&gt; func = lambda it: sum(it)\n&gt;&gt;&gt; func_kwargs = [dict(it=range(i)) for i in range(5)]\n&gt;&gt;&gt; results = multiprocess(func, func_kwargs)\n&gt;&gt;&gt; results\n[FutureResult(exception=None, kwargs={'iterable': range(0, 0)}, result=0),\n FutureResult(exception=None, kwargs={'iterable': range(0, 1)}, result=0),\n FutureResult(exception=None, kwargs={'iterable': range(0, 2)}, result=1),\n FutureResult(exception=None, kwargs={'iterable': range(0, 3)}, result=3),\n FutureResult(exception=None, kwargs={'iterable': range(0, 4)}, result=6)]\n</code></pre> PARAMETER  DESCRIPTION <code>exception</code> <p>Will be <code>None</code> unless an <code>Exception</code> has been raised during the function execution in which case the attribute will contain the exception object.</p> <p> TYPE: <code>Exception | None</code> </p> <code>kwargs</code> <p>May contain the keyword arguments that were used in the function call. If the objects passed as <code>kwargs</code> are too big (RAM-wise), e.g. big dataframes, you can omit them by passing <code>include_kwargs=False</code> in multiprocess/multithread\".</p> <p> TYPE: <code>dict[str, typing.Any] | None</code> </p> <code>result</code> <p>Will contain the function's output. If an <code>Exception</code> has been raised, then it will be <code>None</code>.</p> <p> TYPE: <code>typing.Any</code> </p> Source code in <code>multifutures/_multi.py</code> <pre><code>@dataclasses.dataclass\nclass FutureResult:\n    \"\"\"\n    A [dataclass][dataclasses.dataclass] that holds the results of a function executed via\n    [multiprocess][multifutures.multiprocess] or [multithread][multifutures.multithread].\n\n    Note:\n        Not meant to be instantiated directly.\n\n    For example in the following snippet, `results` is going to be a list of `FutureResult` objects\n\n        &gt;&gt;&gt; func = lambda it: sum(it)\n        &gt;&gt;&gt; func_kwargs = [dict(it=range(i)) for i in range(5)]\n        &gt;&gt;&gt; results = multiprocess(func, func_kwargs)\n        &gt;&gt;&gt; results\n        [FutureResult(exception=None, kwargs={'iterable': range(0, 0)}, result=0),\n         FutureResult(exception=None, kwargs={'iterable': range(0, 1)}, result=0),\n         FutureResult(exception=None, kwargs={'iterable': range(0, 2)}, result=1),\n         FutureResult(exception=None, kwargs={'iterable': range(0, 3)}, result=3),\n         FutureResult(exception=None, kwargs={'iterable': range(0, 4)}, result=6)]\n\n    Parameters:\n        exception:\n            Will be `None` unless an `Exception` has been raised during the function execution\n            in which case the attribute will contain the exception object.\n        kwargs:\n            May contain the keyword arguments that were used in the function call.\n            If the objects passed as `kwargs` are too big (RAM-wise), e.g. big dataframes,\n            you can omit them by passing `include_kwargs=False` in\n            [multiprocess][multifutures.multiprocess]/[multithread][multifutures.multithread]\".\n        result:\n            Will contain the function's output. If an `Exception` has been raised, then it will be `None`.\n    \"\"\"\n\n    exception: Exception | None\n    kwargs: dict[str, T.Any] | None\n    result: T.Any\n</code></pre>"},{"location":"api-multi.html#multifutures.check_results","title":"multifutures.check_results","text":"<pre><code>check_results(results: list[multifutures._multi.FutureResult]) -&gt; None\n</code></pre> <p>Raises an ExceptionGroup if any of the <code>results</code> contains an exception.</p> RAISES DESCRIPTION <code>ExceptionGroup</code> <p>An exception group containing all the individual exceptions. Support for Python &lt; 3.11 is provided via the exceptiongroup package. Check here for more info.</p> Source code in <code>multifutures/_multi.py</code> <pre><code>def check_results(results: list[FutureResult]) -&gt; None:\n    \"\"\"\n    Raises an [ExceptionGroup][ExceptionGroup] if any of the `results` contains an exception.\n\n    Raises:\n        ExceptionGroup: An exception group containing all the individual exceptions.\n            Support for Python &lt; 3.11 is provided via the [exceptiongroup](exceptiongroup) package.\n            Check [here](https://github.com/agronholm/exceptiongroup#catching-exceptions) for more info.\n    \"\"\"\n\n    exceptions = [r.exception for r in results if r.exception is not None]\n    if exceptions:\n        exception_group = exceptiongroup.ExceptionGroup(\"There were exceptions\", exceptions)\n        raise exception_group\n</code></pre>"},{"location":"api-protocols.html","title":"protocols","text":""},{"location":"api-protocols.html#multifutures.ExecutorProtocol","title":"multifutures.ExecutorProtocol","text":"<p>             Bases: <code>typing.Protocol</code></p>"},{"location":"api-protocols.html#multifutures.ExecutorProtocol.__enter__","title":"__enter__","text":"<pre><code>__enter__() -&gt; typing_extensions.Self\n</code></pre>"},{"location":"api-protocols.html#multifutures.ExecutorProtocol.__exit__","title":"__exit__","text":"<pre><code>__exit__(\n    exc_type: type[BaseException] | None,\n    exc_val: BaseException | None,\n    exc_tb: types.TracebackType | None,\n) -&gt; bool | None\n</code></pre>"},{"location":"api-protocols.html#multifutures.ExecutorProtocol.submit","title":"submit","text":"<pre><code>submit(\n    fn: typing.Callable[..., typing.Any],\n    /,\n    *args: typing.Any,\n    **kwargs: typing.Any,\n) -&gt; concurrent.futures.Future[typing.Any]\n</code></pre>"},{"location":"api-protocols.html#multifutures.ProgressBarProtocol","title":"multifutures.ProgressBarProtocol","text":"<p>             Bases: <code>typing.Protocol</code></p>"},{"location":"api-protocols.html#multifutures.ProgressBarProtocol.__enter__","title":"__enter__","text":"<pre><code>__enter__() -&gt; typing_extensions.Self\n</code></pre>"},{"location":"api-protocols.html#multifutures.ProgressBarProtocol.__exit__","title":"__exit__","text":"<pre><code>__exit__(\n    exc_type: type[BaseException] | None,\n    exc_value: BaseException | None,\n    traceback: types.TracebackType | None,\n) -&gt; bool | None\n</code></pre>"},{"location":"api-protocols.html#multifutures.ProgressBarProtocol.close","title":"close","text":"<pre><code>close() -&gt; None\n</code></pre>"},{"location":"api-protocols.html#multifutures.ProgressBarProtocol.update","title":"update","text":"<pre><code>update(n: float | None) -&gt; bool | None\n</code></pre>"},{"location":"api-rate_limit.html","title":"rate_limit","text":""},{"location":"api-rate_limit.html#multifutures.wait","title":"multifutures.wait","text":"<pre><code>wait(wait_time: float = 0.1, *, jitter: bool = True) -&gt; None\n</code></pre> <p>Wait for <code>wait_time</code> + some random <code>jitter</code></p> Source code in <code>multifutures/_rate_limit.py</code> <pre><code>def wait(wait_time: float = 0.1, *, jitter: bool = True) -&gt; None:\n    \"\"\"Wait for `wait_time` + some random `jitter`\"\"\"\n    if jitter:\n        # Set jitter to be &lt;= 1% of wait_time\n        jitter_time = random.random() / (1 / wait_time * 100)  # noqa: S311 - suspicious-non-cryptographic-random-usage\n    else:\n        jitter_time = 0\n    time.sleep(wait_time + jitter_time)\n</code></pre>"},{"location":"api-rate_limit.html#multifutures.RateLimit","title":"multifutures.RateLimit","text":"<p>A wrapper around the limits library. It defaults to using the Moving Window Strategy on the Memory Storage.</p> Warning <p>The default strategy only works with multi-threading, not multi-processing. If you want to use it with multiprocessing you need to use a different storage backend (e.g. redis).</p>"},{"location":"api-rate_limit.html#multifutures.RateLimit--usage","title":"Usage","text":"<pre><code>rate_limit = RateLimit()\n\nwhile rate_limit.reached():\n    wait()\n</code></pre> PARAMETER  DESCRIPTION <code>rate_limit</code> <p>The rate limit. An instance of limits.parse. Defaults to 5 requests per seconds.</p> <p> TYPE: <code>limits.RateLimitItem | None</code> DEFAULT: <code>None</code> </p> <code>strategy</code> <p>The strategy to use. Defaults to a Moving Window using the Memory Storage.</p> <p> TYPE: <code>limits.strategies.RateLimiter | None</code> DEFAULT: <code>None</code> </p> Source code in <code>multifutures/_rate_limit.py</code> <pre><code>class RateLimit:\n    \"\"\"\n    A wrapper around the [limits](https://limits.readthedocs.io/en/stable/index.html) library.\n    It defaults to using the [Moving Window Strategy][limits.strategies.MovingWindowRateLimiter]\n    on the [Memory Storage][limits.storage.MemoryStorage].\n\n    Warning:\n        The default strategy only works with multi-threading, not multi-processing.\n        If you want to use it with multiprocessing you need to use a different storage backend (e.g. redis).\n\n    ## Usage\n\n        rate_limit = RateLimit()\n\n        while rate_limit.reached():\n            wait()\n\n    Arguments:\n        rate_limit: The rate limit. An instance of [limits.parse][limits.parse].\n            Defaults to 5 requests per seconds.\n        strategy: The strategy to use. Defaults to a Moving Window using the Memory Storage.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        rate_limit: limits.RateLimitItem | None = None,\n        strategy: limits.strategies.RateLimiter | None = None,\n    ) -&gt; None:\n        import limits\n\n        self.rate_limit = rate_limit or limits.parse(\"5/second\")\n        if strategy is None:\n            storage = limits.storage.MemoryStorage()\n            strategy = limits.strategies.MovingWindowRateLimiter(storage)\n        self.strategy = strategy\n\n    def reached(self, identifier: str = \"\") -&gt; bool:\n        \"\"\"\n        Returns `True` if the rate limit has been reached, `False` otherwise.\n\n        `RateLimit` instances can be reused in different contexts.\n        To do so a unique identifier per-context must be provided.\n\n        Arguments:\n            identifier: The identifier allows you to reuse the `RateLimit` instance in different contexts.\n\n        \"\"\"\n        return not self.strategy.hit(\n            self.rate_limit,\n            identifier,\n        )\n</code></pre>"},{"location":"api-rate_limit.html#multifutures.RateLimit.reached","title":"reached","text":"<pre><code>reached(identifier: str = '') -&gt; bool\n</code></pre> <p>Returns <code>True</code> if the rate limit has been reached, <code>False</code> otherwise.</p> <p><code>RateLimit</code> instances can be reused in different contexts. To do so a unique identifier per-context must be provided.</p> PARAMETER  DESCRIPTION <code>identifier</code> <p>The identifier allows you to reuse the <code>RateLimit</code> instance in different contexts.</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> Source code in <code>multifutures/_rate_limit.py</code> <pre><code>def reached(self, identifier: str = \"\") -&gt; bool:\n    \"\"\"\n    Returns `True` if the rate limit has been reached, `False` otherwise.\n\n    `RateLimit` instances can be reused in different contexts.\n    To do so a unique identifier per-context must be provided.\n\n    Arguments:\n        identifier: The identifier allows you to reuse the `RateLimit` instance in different contexts.\n\n    \"\"\"\n    return not self.strategy.hit(\n        self.rate_limit,\n        identifier,\n    )\n</code></pre>"},{"location":"installation.html","title":"Installation","text":""},{"location":"installation.html#installation","title":"Installation","text":""},{"location":"installation.html#pypi","title":"PyPI","text":"<pre><code>python -m pip install multifutures\n</code></pre>"},{"location":"installation.html#conda","title":"conda","text":"<p>Soon</p>"}]}